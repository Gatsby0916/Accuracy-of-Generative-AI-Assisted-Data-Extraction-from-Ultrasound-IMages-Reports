# Accuracy of Generative AI–Assisted Data Extraction from Ultrasound Image Reports

## Project Overview

This repository demonstrates how to leverage large language models (LLMs) such as OpenAI GPT-4 Turbo to automatically extract structured data from locally stored medical report images—primarily MRI reports—and compare the results against human‐annotated ground truth. The aim is to reduce repetitive data‐entry work for healthcare professionals and quantitatively assess the accuracy of AI‐assisted extraction in real‐world clinical scenarios.

## Key Features

* **PDF → Image Conversion**: Convert PDF reports to PNG for image‐based processing.
* **Data Preparation**: Clean and standardize ground truth Excel data; generate JSON templates to enforce consistent LLM output.
* **LLM‑Based Extraction**: Send report images and JSON templates to the OpenAI API (GPT‑4 Turbo) and receive structured JSON data.
* **Result Validation & Correction**: Compare raw LLM output against the template; automatically fix minor key mismatches (e.g., typos) and fill missing fields.
* **Format Conversion**: Transform validated JSON into Excel for easier review and post‐processing.
* **Accuracy Evaluation**: Compare each cell in the LLM‐extracted Excel against the ground truth; compute precision at the field level.
* **Discrepancy Reporting**: Generate detailed text reports listing all mismatches, including original vs. extracted values.
* **Aggregate Analysis**: Read individual accuracy files, compute statistics (mean, median, standard deviation), and produce visual summaries.

## Directory Structure

```text
LLM-test/
├── .env                  # Environment variables (create this file manually)
├── .gitignore            # Git ignore rules
├── requirements.txt      # Python dependencies
├── README.md             # Project documentation (this file)
├── data/                 # Raw inputs and templates
│   ├── ground_truth/     # Put your Excel ground truth files here
│   ├── raw_reports/      # Put your PDF reports here (subfolders allowed)
│   └── templates/        # JSON templates (can be generated by scripts)
├── results/              # All outputs (ignored by Git)
│   ├── accuracy_reports/ # Text reports of per‐file accuracy
│   ├── extracted_data/   # LLM results:
│   │   ├── excel/        # Converted Excel files
│   │   ├── json_checked/ # Validated JSON
│   │   └── json_raw/     # Raw JSON output
│   ├── overall_analysis/ # Aggregate charts and statistics
│   └── processed_images/ # PNGs generated from PDFs
├── src/                  # Python source code
│   ├── __init__.py
│   ├── api_interaction.py
│   ├── config.py         # Path and environment configuration
│   ├── data_conversion.py
│   ├── data_extraction.py
│   ├── data_validation.py
│   ├── evaluation.py
│   ├── json_to_excel.py
│   ├── main.py           # Main workflow
│   └── reporting.py      # Aggregate reporting
└── venv/                 # Python virtual environment (ignored by Git)
```

## Installation & Setup

1. **Clone or Download the Repository**

   ```bash
   git clone <repository‑URL>
   cd LLM-test
   ```

2. **Create & Activate a Python Virtual Environment**
   (Recommended: Python 3.7 or later)

   ```bash
   # Windows PowerShell
   python -m venv venv
   .\venv\Scripts\Activate.ps1

   # macOS / Linux
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install Dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **(Windows-only) Install Poppler for PDF Conversion**
   The `pdf2image` library requires Poppler on Windows:

   1. Download from [https://github.com/oschwartz10612/poppler-windows/releases](https://github.com/oschwartz10612/poppler-windows/releases).
   2. Unzip to `C:\Program Files\poppler-<version>`.
   3. Add the `bin` folder (e.g., `C:\Program Files\poppler-<version>\bin`) to your PATH.
   4. Restart your terminal.
      On macOS: `brew install poppler`
      On Ubuntu: `sudo apt-get install poppler-utils`

5. **Configure Environment Variables**
   Create a `.env` file in the project root with your OpenAI key:

   ```dotenv
   OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
   ```

6. **Prepare Your Data & Update Paths**

   * Place your ground truth Excel in `data/ground_truth/`.
   * Place your PDF reports in `data/raw_reports/`.
   * Edit `src/config.py` to point to:

     * `ORIGINAL_GROUND_TRUTH_XLSX`
     * `DEFAULT_PDF_SCAN_DIR`
     * Other relevant paths as needed.

## Usage Workflow

*Run all commands from the project root with the virtual environment activated.*

1. **Preprocessing**

   * Clean ground truth & generate JSON template:

     ```bash
     python src/data_extraction.py
     ```
   * Convert PDFs → PNGs:

     ```bash
     python src/data_conversion.py
     ```

2. **Full Extraction & Evaluation**

   ```bash
   python src/main.py
   ```

   * To process specific files:

     ```bash
     python src/main.py -i REPORT_ID_1 REPORT_ID_2
     ```
   * To specify another PDF directory:

     ```bash
     python src/main.py --pdf-dir "data/raw_reports/CustomFolder"
     ```

3. **Aggregate Summary**

   ```bash
   python src/reporting.py
   ```

All intermediate and final outputs will be stored under `results/`.

## Dependencies

All required packages and versions are listed in `requirements.txt`. Install them via:

```bash
pip install -r requirements.txt
```
